## Модуль 2. Фреймворк для распределенных вычислений Apache Spark

### Занятие 5. Введение в Scala.

#### Цель занятия

*   Изучить основы языка Scala
*   Научиться собирать простейшее Scala-приложение

#### Краткое содержание

*   Синтаксис и простые выражения в Scala
*   Управляющие конструкции: if, for, pattern matching
*   ООП: Class, Object, Trait
*   Implicits
*   Инструменты для разработки: sbt, IntelliJ IDEA

#### Результат

- Приложение на языке Scala

### Занятие 6. Apache Spark - 1 часть.

- Spark - что это и зачем он нужен
- API - RDD, Dataset, Dataframe, операции над распределенными коллекциями
- Процесс вычисления в Spark - task, stage, оптимизатор запросов

### Занятие 7. Apache Spark - 2 часть.

- Spark - что это и зачем он нужен
- API - RDD, Dataset, Dataframe, операции над распределенными коллекциями
- Процесс вычисления в Spark - task, stage, оптимизатор запросов

#### [Домашнeе заданиe № 3. Введение в Spark + Гид по безопасному Бостону](./hw-3-spark/)

### Занятие 8. Spark Streaming.

- Micro-batch обработка данных
- Классический Spark Streaming
- Structured Streaming
- Continuous processing

### Занятие 8. Jupyter Notebook. Интерактивная аналитика и визуализация.

- Инструменты интерактивной аналитики
- Google Cloud Datalab
- Jupyter - интеграция с Apache Spark

### Занятие 9. Spark Streaming.

- Micro-batch обработка данных
- Классический Spark Streaming
- Structured Streaming
- Continuous processing

### Занятие 10. Очереди сообщений, Kafka, Confluent platform.

- Kafka, RabbitMQ
- Потоковая обработка (виды обработки, описание Producer–consumer problem, пример архитектурного решения через Kafka, RabbitMQ, NATS)
- Google Dataflow paper (Event time vs processing time и так далее).
- Паттерны stream processing Joins, enricher, router. Event-sourcing.